//! Garbage-Collected smart pointers with interior mutability.
//!
//! Gc<T> is conceptually similar to Arc<tokio::sync::RwLock<T>>, but garbage
//! collection occurs concurrently at a fixed cadence or whenever a threshold
//! of memory has been allocated as opposed to when the type is Dropped.
//!
//! Strictly speaking, Gc<T> is not garbage collection per-se but instead uses 
//! "cycle collection". 
//!
//! Cycle collection was chosen because it has similar characteristics to Gc,
//! providing all of the semantics Scheme expects data to have and also plays
//! nicely as a Rust type.
//!
//! 

use std::{
    cell::UnsafeCell,
    collections::HashMap,
    marker::PhantomData,
    ops::{Deref, DerefMut},
    ptr::NonNull,
    sync::{
        atomic::{self, Ordering},
        Arc,
    },
};
use tokio::sync::{RwLock, Semaphore, SemaphorePermit};

/// A Garbage-Collected smart pointer with interior mutability.
pub struct Gc<T: ?Sized> {
    ptr: NonNull<GcInner<T>>,
    marker: PhantomData<Arc<RwLock<T>>>,
}

impl<T: ?Sized> Gc<T> {
    pub fn as_ptr(&self) -> *const GcInner<T> {
        self.ptr.as_ptr()
    }
}

impl<T> Gc<T> {
    pub fn new(t: T) -> Gc<T> {
        Self {
            ptr: NonNull::from(Box::leak(Box::new(GcInner {
                roots: atomic::AtomicUsize::new(1),
                semaphore: Semaphore::new(MAX_READS as usize),
                data: UnsafeCell::new(t),
            }))),
            marker: PhantomData,
        }
    }
}

impl<T: ?Sized> Gc<T> {
    unsafe fn to_inner(&self) -> &GcInner<T> {
        self.ptr.as_ref()
    }

    pub async fn read(&self) -> GcReadGuard<'_, T> {
        unsafe { self.to_inner().read().await }
    }

    pub async fn write(&self) -> GcWriteGuard<'_, T> {
        unsafe { self.to_inner().write().await }
    }
}

impl<T: ?Sized> Clone for Gc<T> {
    fn clone(&self) -> Gc<T> {
        unsafe { self.ptr.as_ref().inc_roots() }
        Self {
            ptr: self.ptr,
            marker: PhantomData,
        }
    }
}

enum Color {
    /// In use or free
    Black,
    /// Possible member of a cycle
    Gray,
    /// Member of a garbage cycle
    White,
    /// Possible root of cycle
    Purple,
    /// Acyclic
    Green,
    /// Candidate cycle undergoing Î£-computation
    Red,
    /// Candidate cycle awaiting epoch boundary
    Orange
}

const MAX_READS: u32 = u32::MAX >> 3;

pub struct GcInner<T: ?Sized> {
    rc: atomic::AtomicUsize,
    color: Color,
    semaphore: Semaphore,
    data: UnsafeCell<T>,
}

impl<T: ?Sized> GcInner<T> {
    fn inc_ref_count(&self) {
        self.rc.fetch_add(1, Ordering::Relaxed);
    }

    fn dec_ref_count(&self) {
        self.rc.fetch_sub(1, Ordering::Release);
    }

    async fn read(&self) -> GcReadGuard<'_, T> {
        let _permit = self.semaphore.acquire().await.unwrap();
        let data = self.data.get() as *const T;
        GcReadGuard {
            _permit,
            data,
            marker: PhantomData,
        }
    }
}

impl<T: ?Sized + Trace> GcInner<T> {
    async fn write(&self) -> GcWriteGuard<'_, T> {
        unsafe { (*self.data.get()).root() }
        let _permit = self.semaphore.acquire_many(MAX_READS).await.unwrap();
        let data = self.data.get();
        GcWriteGuard {
            _permit,
            data,
            marker: PhantomData,
        }
    }
}


unsafe impl<T: ?Sized + Send + Sync> Send for GcInner<T> {}
unsafe impl<T: ?Sized + Send + Sync> Sync for GcInner<T> {}

pub struct GcReadGuard<'a, T: ?Sized> {
    _permit: SemaphorePermit<'a>,
    data: *const T,
    marker: PhantomData<&'a T>,
}

impl<'a, T: ?Sized> Deref for GcReadGuard<'a, T> {
    type Target = T;

    fn deref(&self) -> &T {
        unsafe { &*self.data }
    }
}

impl<'a, T: ?Sized> AsRef<T> for GcReadGuard<'a, T> {
    fn as_ref(&self) -> &T {
        self
    }
}

unsafe impl<T: ?Sized + Send + Sync> Send for GcReadGuard<'_, T> {}
unsafe impl<T: ?Sized + Send + Sync> Sync for GcReadGuard<'_, T> {}

pub struct GcWriteGuard<'a, T: ?Sized + Trace> {
    _permit: SemaphorePermit<'a>,
    data: *mut T,
    marker: PhantomData<&'a mut T>,
}

impl<'a, T: ?Sized + Trace> Deref for GcWriteGuard<'a, T> {
    type Target = T;

    fn deref(&self) -> &T {
        unsafe { &*self.data }
    }
}

impl<'a, T: ?Sized + Trace> DerefMut for GcWriteGuard<'a, T> {
    fn deref_mut(&mut self) -> &mut T {
        unsafe { &mut *self.data }
    }
}

impl<'a, T: ?Sized + Trace> Drop for GcWriteGuard<'a, T> {
    fn drop(&mut self) {
        unsafe { (*self.data).unroot() }
    }
}

impl<T: ?Sized + Trace> Trace for Gc<T> {
    fn unroot(&self) {
        unsafe { self.ptr.as_ref().dec_roots() }
    }
}
*/

unsafe impl<T: ?Sized + Send + Sync> Send for Gc<T> {}
unsafe impl<T: ?Sized + Send + Sync> Sync for Gc<T> {}
